{
  "name": "Accident Classification of Steel Plant",
  "tagline": "Academic Project 1&2",
  "body": "# Introduction\r\n\r\nThis is a part of a consulting project given by Tata Steel to Industrial Engineering Dept. IIT Kharagpur to analyse the huge textual data related to the accidents that occurred or did not occur in the past 4 years. \r\nThere are two types of input text .csv files, \r\n\r\n1. Description of event where accident actually occurred. \r\n2. Description of event where accident could have happened, but was missed due to precautions.\r\n\r\nThe description tells us about the environmental factors responsible for the hazard and the target human.\r\n\r\nAll of the coding work is fulfilled using R programming language. the code is rather simple with the use of available libraries to handle the textual data.\r\n\r\n\r\nPS. this is the first ever project related to data analytics. So, I had no prior experience in this task beforehand.\r\n\r\n#  Task Summary\r\n\r\n1. Input the data files and make the text corpus.\r\n2. Implement prediction models to forecast the chances of accidents to happen for testing data set (description).\r\n3. Further predict the class (or category) of accident (eg. Slip/Fall/ Fire Explosion/ Leakage etc.)\r\n\r\n\r\n#  Process Flow\r\n\r\n1. the data files are read and converted to Text Corpus using TM library in R.\r\n2. after the creation of Term Document Matrix with normalized TF-IDF, the data features with less frequency are removed to reduce the sparsity of data.\r\n3. Applied the following Machine Learning Models for the classification process of accidents and non accidents.\r\ni. KNN\r\nii. Random Forest.\r\niii. SVM.\r\niv. Maximum Entropy.\r\n\r\n4.  Next the results were concluded using the Confusion Matrix, with which we get the accuracy, precision, recall and F score. Moreover ROC is also built in each case.\r\n\r\n###  Honest Flaw in the Approach\r\n\r\nSince, I was a newbie at that time, I didn't know anything about Word2Vec or ngram. etc topics or parameter tuning of classifiers, the accuracy was not high. \r\n\r\n# Code\r\n    setwd(\"C:/Users/Vishal Lakha/Desktop/project\")\r\n    library(httr)\r\n    set_config(use_proxy(url=\"10.3.100.207\", port=8080))\r\n    library(tm)\r\n    library(class)\r\n    library(e1071)\r\n    library(wordcloud)\r\n    library(ggplot2)\r\n    library(ROCR)\r\n    require(graphics)\r\n    library(cluster)\r\n    library(fpc) \r\n    library(factoextra)\r\n    library(caret)\r\n    library(pracma)\r\n    library(gmodels)\r\n    library(ROCR)\r\n    library(FSelector)\r\n    library(cvTools)\r\n    # install.packages(\"devtools\")\r\n    # library(devtools)\r\n    # install_github(\"kassambara/factoextra\")\r\n    \r\n    \r\n    \r\n    #Pre-processing\r\n    library(tm)\r\n    reviews <- read.csv (\"data for matrix.csv\", stringsAsFactors=FALSE, header = F)\r\n    review_source <- VectorSource(reviews)\r\n    corpus <- Corpus(review_source)\r\n    corpus <- tm_map(corpus, content_transformer(tolower))\r\n    corpus <- tm_map(corpus, removePunctuation)\r\n    corpus <- tm_map(corpus, stripWhitespace)\r\n    corpus=tm_map(corpus, function(x) removeWords(x, stopwords(\"english\")))\r\n    corpus=tm_map(corpus, function(x) removeWords(x, stopwords(\"en\")))\r\n    corpus=tm_map(corpus, function(x) removeWords(x, stopwords(\"SMART\")))\r\n    corpus=tm_map(corpus, function(x) removeWords(x, stopwords(\"german\")))\r\n    corpus <- tm_map(corpus, removeNumbers)\r\n    corpus <- tm_map(corpus, stemDocument, language=\"english\")\r\n    #TF-IDF score\r\n    dtm = DocumentTermMatrix(corpus,control=list(bounds = list(global = c(18,Inf)), weighting = function(x) weightTfIdf(x, normalize = TRUE)))\r\n    dtm_matrix <- as.matrix(dtm)\r\n    \r\n    #Frequency Matrix\r\n    frequency <- colSums(dtm_matrix)\r\n    frequency <- sort(frequency, decreasing=TRUE)\r\n    head(frequency)\r\n    \r\n    #KNN CLASSIFICATION (K=5)\r\n    train<-dtm_matrix[1:4960,]\r\n    test<-dtm_matrix[4961:6611,]\r\n    prevdata<-read.csv(\"training classified.csv\",header= F)$V1\r\n    prediction<-knn(train,test,cl=prevdata,k=5)\r\n    actual<-read.csv(\"testing classified.csv\",header= F)$V1\r\n    \r\n    prednew<-as.vector(prediction)\r\n    actnew<-as.vector(actual)\r\n    \r\n    \r\n    library(tm)\r\n    library(RTextTools)\r\n    dim(dtm_matrix)\r\n    \r\n    container <- create_container(dtm_matrix, prevdata, trainSize=1:4960,testSize=4961:6611, virgin=T)\r\n    \r\n    SVM <- train_model(container,\"SVM\")\r\n    MAXENT <- train_model(container,\"MAXENT\", l1_regularizer = 1,le_regularizer=1, use_sgd = T)\r\n    RF<-train_model(container,\"RF\")\r\n    \r\n    \r\n    SVM_CLASSIFY <- classify_model(container, SVM)\r\n    MAXENT_CLASSIFY <- classify_model(container, MAXENT)\r\n    RF_CLASSIFY <- classify_model(container, RF)\r\n    \r\n    prednew1<-SVM_CLASSIFY$SVM_LABEL\r\n    prednew2<-MAXENT_CLASSIFY$MAXENTROPY_LABEL\r\n    prednew3<-RF_CLASSIFY$FORESTS_LABEL\r\n    \r\n    cm<-confusionMatrix(prednew,actnew)\r\n    cm1<-confusionMatrix(prednew1,actnew)\r\n    cm2<-confusionMatrix(prednew2,actnew)\r\n    cm3<-confusionMatrix(prednew3,actnew)\r\n    \r\n    \r\n    library(pROC)\r\n    paste(\"auc knn\",auc(as.ordered(actual),as.ordered(prediction)))\r\n    paste(\"auc svm\",auc(as.ordered(actual),as.ordered(prednew1)))\r\n    paste(\"auc maxent\",auc(as.ordered(actual),as.ordered(prednew2)))\r\n    paste(\"auc rf\",auc(as.ordered(actual),as.ordered(prednew3)))\r\n    \r\n    plot.roc(as.ordered(actual),as.ordered(prediction))\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}